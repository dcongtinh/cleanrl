{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51406ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n",
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "from evaluation import *\n",
    "\n",
    "\n",
    "# SEED = 0\n",
    "# random.seed(1)\n",
    "# np.random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# model_path = \"/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/3gradcaps/SAC-3gradcaps-lmd0.1-walker-run-v0-seed1-2025_09_30_14h50m11s__minmax/weights/best_reward-799.5089_smooth-37.5638.w\"\n",
    "# _ = evaluate(\n",
    "#     model_path,\n",
    "#     make_env,\n",
    "#     \"dm_control/walker-run-v0\",\n",
    "#     eval_episodes=10,\n",
    "#     run_name=f\"eval\",\n",
    "#     device=\"cuda\",\n",
    "#     capture_video=False,\n",
    "#     seed=SEED\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d548629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "filenames = glob('/home/adsl/Workspace/cleanrl/cleanrl/runs/**', recursive=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b30c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# algo = 'TD3'\n",
    "# model = '-3gradcaps-'\n",
    "# env = 'walker-run-v0'\n",
    "\n",
    "# if algo == 'SAC':\n",
    "#     from cleanrl.sac_continuous_action import Actor, make_env\n",
    "# elif algo == 'TD3':\n",
    "#     from cleanrl.td3_continuous_action import Actor, make_env\n",
    "# elif algo == 'DDPG':\n",
    "#     from cleanrl.ddpg_continuous_action import Actor, make_env\n",
    "\n",
    "# best_reward = -10000\n",
    "\n",
    "# for filename in filenames:\n",
    "#     if (algo in filename) and (model in filename) and env in filename and 'best_reward' in filename:\n",
    "#         reward = float(filename.split('best_reward-')[-1].split('_')[0])\n",
    "#         smooth = float(filename.split('smooth-')[-1].split('.w')[0])\n",
    "#         if reward > best_reward:\n",
    "#             best_reward = reward\n",
    "#             best_filename = filename\n",
    "\n",
    "# print(best_filename)\n",
    "# best_reward = -10000\n",
    "\n",
    "# for seed in range(10):\n",
    "#     rewards, smooths1, smooths2, smooths3 = evaluate(\n",
    "#         best_filename,\n",
    "#         make_env,\n",
    "#         \"dm_control/walker-run-v0\",\n",
    "#         eval_episodes=10,\n",
    "#         run_name=f\"eval\",\n",
    "#         device=\"cuda\",\n",
    "#         capture_video=False,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     print()\n",
    "\n",
    "#     reward = np.mean(rewards)\n",
    "    \n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_rewards = rewards\n",
    "#         best_smooths1 = smooths1\n",
    "#         best_smooths2 = smooths2\n",
    "#         best_smooths3 = smooths3\n",
    "#         best_seed = seed\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(f'Best Reward: {np.mean(best_rewards):.6f} ± {np.std(best_rewards):.6f}')\n",
    "# print(f'Best Smooth1: {np.mean(best_smooths1)*100:.6f} ± {np.std(best_smooths1)*100:.6f}')\n",
    "# print(f'Best Smooth2: {np.mean(best_smooths2)*100:.6f} ± {np.std(best_smooths2)*100:.6f}')\n",
    "# print(f'Best Smooth3: {np.mean(best_smooths3):.6f} ± {np.std(best_smooths3):.6f}')\n",
    "# print('Best Seed:', best_seed)\n",
    "# # print(best_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─ </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Unrecognized options</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> Unrecognized options:                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> --f=/run/user/1000/jupyter/runtime/kernel-v3e197d837517d47cca9e0c21b56f64c362693242b.json <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">─────────────────────────────────────────────────────────────────────────────────────────</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> For full helptext, run <span style=\"font-weight: bold\">ipykernel_launcher.py --help</span>                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭─\u001b[0m\u001b[91m \u001b[0m\u001b[1;91mUnrecognized options\u001b[0m\u001b[91m ───────────────────────────────────────────────────────────────────\u001b[0m\u001b[91m─╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m Unrecognized options:                                                                     \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m --f=/run/user/1000/jupyter/runtime/kernel-v3e197d837517d47cca9e0c21b56f64c362693242b.json \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m \u001b[31m─────────────────────────────────────────────────────────────────────────────────────────\u001b[0m \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m For full helptext, run \u001b[1mipykernel_launcher.py --help\u001b[0m                                       \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/SAC-vanilla-lmd0.1-walker-run-v0-seed1-2025_09_29_17h00m42s__test/weights/best_reward-783.4902_smooth-37.4868.w\n",
      "Eval over 10 episodes: mean reward 780.834534 ± 15.125390\n",
      "Eval over 10 episodes: mean smooth 37.437382 ± 0.341083\n",
      "Eval over 10 episodes: mean smoot2 1.137430 ± 0.184080\n",
      "Eval over 10 episodes: mean smooth3 2.837888 ± 0.033013\n",
      "\n",
      "Eval over 10 episodes: mean reward 782.185181 ± 9.295474\n",
      "Eval over 10 episodes: mean smooth 37.682956 ± 0.394749\n",
      "Eval over 10 episodes: mean smoot2 1.142581 ± 0.188719\n",
      "Eval over 10 episodes: mean smooth3 2.850740 ± 0.039662\n",
      "\n",
      "Eval over 10 episodes: mean reward 776.951050 ± 11.171747\n",
      "Eval over 10 episodes: mean smooth 37.643772 ± 0.533993\n",
      "Eval over 10 episodes: mean smoot2 1.141986 ± 0.184438\n",
      "Eval over 10 episodes: mean smooth3 2.849255 ± 0.045646\n",
      "\n",
      "Eval over 10 episodes: mean reward 783.717712 ± 9.306509\n",
      "Eval over 10 episodes: mean smooth 37.713453 ± 0.319186\n",
      "Eval over 10 episodes: mean smoot2 1.141210 ± 0.194318\n",
      "Eval over 10 episodes: mean smooth3 2.847320 ± 0.028852\n",
      "\n",
      "Eval over 10 episodes: mean reward 778.884644 ± 8.668163\n",
      "Eval over 10 episodes: mean smooth 37.435144 ± 0.426413\n",
      "Eval over 10 episodes: mean smoot2 1.135016 ± 0.188886\n",
      "Eval over 10 episodes: mean smooth3 2.831866 ± 0.043086\n",
      "\n",
      "Eval over 10 episodes: mean reward 775.454407 ± 10.912707\n",
      "Eval over 10 episodes: mean smooth 37.505227 ± 0.238180\n",
      "Eval over 10 episodes: mean smoot2 1.140150 ± 0.185768\n",
      "Eval over 10 episodes: mean smooth3 2.844674 ± 0.024442\n",
      "\n",
      "Eval over 10 episodes: mean reward 780.900513 ± 14.352541\n",
      "Eval over 10 episodes: mean smooth 37.725559 ± 0.597789\n",
      "Eval over 10 episodes: mean smoot2 1.143291 ± 0.178234\n",
      "Eval over 10 episodes: mean smooth3 2.852512 ± 0.051850\n",
      "\n",
      "Eval over 10 episodes: mean reward 768.772156 ± 13.440030\n",
      "Eval over 10 episodes: mean smooth 37.617588 ± 0.612604\n",
      "Eval over 10 episodes: mean smoot2 1.140791 ± 0.186358\n",
      "Eval over 10 episodes: mean smooth3 2.846273 ± 0.058172\n",
      "\n",
      "Eval over 10 episodes: mean reward 779.218262 ± 10.390285\n",
      "Eval over 10 episodes: mean smooth 37.665248 ± 0.305766\n",
      "Eval over 10 episodes: mean smoot2 1.141396 ± 0.180523\n",
      "Eval over 10 episodes: mean smooth3 2.847782 ± 0.035313\n",
      "\n",
      "Eval over 10 episodes: mean reward 783.252319 ± 9.235033\n",
      "Eval over 10 episodes: mean smooth 37.640887 ± 0.607658\n",
      "Eval over 10 episodes: mean smoot2 1.143112 ± 0.191242\n",
      "Eval over 10 episodes: mean smooth3 2.852063 ± 0.039169\n",
      "\n",
      "\n",
      "Best Reward: 783.717712 ± 9.306509\n",
      "Best Smooth1: 37.713453 ± 0.319186\n",
      "Best Smooth2: 1.141210 ± 0.194318\n",
      "Best Smooth3: 2.847320 ± 0.028852\n",
      "Best Seed: 3\n",
      "/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/caps/SAC-caps-lmd0.1-walker-run-v0-seed1-2025_09_30_01h05m28s__notOMU/weights/best_reward-724.7533_smooth-35.7550.w\n",
      "Eval over 10 episodes: mean reward 725.564270 ± 10.159088\n",
      "Eval over 10 episodes: mean smooth 35.755548 ± 0.479359\n",
      "Eval over 10 episodes: mean smoot2 1.039807 ± 0.080785\n",
      "Eval over 10 episodes: mean smooth3 2.594318 ± 0.044676\n",
      "\n",
      "Eval over 10 episodes: mean reward 724.541321 ± 6.832730\n",
      "Eval over 10 episodes: mean smooth 35.839671 ± 0.386153\n",
      "Eval over 10 episodes: mean smoot2 1.044516 ± 0.087370\n",
      "Eval over 10 episodes: mean smooth3 2.606068 ± 0.038200\n",
      "\n",
      "Eval over 10 episodes: mean reward 719.904175 ± 6.476846\n",
      "Eval over 10 episodes: mean smooth 35.924163 ± 0.513286\n",
      "Eval over 10 episodes: mean smoot2 1.045885 ± 0.091602\n",
      "Eval over 10 episodes: mean smooth3 2.609482 ± 0.043479\n",
      "\n",
      "Eval over 10 episodes: mean reward 723.861328 ± 8.063980\n",
      "Eval over 10 episodes: mean smooth 35.699949 ± 0.264137\n",
      "Eval over 10 episodes: mean smoot2 1.045280 ± 0.086544\n",
      "Eval over 10 episodes: mean smooth3 2.607972 ± 0.019301\n",
      "\n",
      "Eval over 10 episodes: mean reward 717.358215 ± 13.667194\n",
      "Eval over 10 episodes: mean smooth 35.958210 ± 0.431885\n",
      "Eval over 10 episodes: mean smoot2 1.052919 ± 0.084156\n",
      "Eval over 10 episodes: mean smooth3 2.627033 ± 0.040005\n",
      "\n",
      "Eval over 10 episodes: mean reward 716.564148 ± 17.017307\n",
      "Eval over 10 episodes: mean smooth 35.715896 ± 0.435240\n",
      "Eval over 10 episodes: mean smoot2 1.046320 ± 0.082397\n",
      "Eval over 10 episodes: mean smooth3 2.610567 ± 0.035906\n",
      "\n",
      "Eval over 10 episodes: mean reward 724.761353 ± 7.937181\n",
      "Eval over 10 episodes: mean smooth 35.865888 ± 0.442946\n",
      "Eval over 10 episodes: mean smoot2 1.037326 ± 0.086579\n",
      "Eval over 10 episodes: mean smooth3 2.588128 ± 0.028590\n",
      "\n",
      "Eval over 10 episodes: mean reward 717.653442 ± 4.846986\n",
      "Eval over 10 episodes: mean smooth 35.916874 ± 0.504256\n",
      "Eval over 10 episodes: mean smoot2 1.049689 ± 0.090809\n",
      "Eval over 10 episodes: mean smooth3 2.618974 ± 0.050211\n",
      "\n",
      "Eval over 10 episodes: mean reward 724.965393 ± 8.713345\n",
      "Eval over 10 episodes: mean smooth 35.696173 ± 0.473578\n",
      "Eval over 10 episodes: mean smoot2 1.039945 ± 0.090827\n",
      "Eval over 10 episodes: mean smooth3 2.594663 ± 0.038324\n",
      "\n",
      "Eval over 10 episodes: mean reward 722.961670 ± 7.482082\n",
      "Eval over 10 episodes: mean smooth 35.881659 ± 0.387639\n",
      "Eval over 10 episodes: mean smoot2 1.044557 ± 0.085577\n",
      "Eval over 10 episodes: mean smooth3 2.606169 ± 0.028475\n",
      "\n",
      "\n",
      "Best Reward: 725.564270 ± 10.159088\n",
      "Best Smooth1: 35.755548 ± 0.479359\n",
      "Best Smooth2: 1.039807 ± 0.080785\n",
      "Best Smooth3: 2.594318 ± 0.044676\n",
      "Best Seed: 0\n",
      "/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/gradcaps/SAC-gradcaps-lmd0.1-walker-run-v0-seed1-2025_09_29_22h46m24s__notOMU/weights/best_reward-791.4159_smooth-36.3905.w\n",
      "Eval over 10 episodes: mean reward 793.139587 ± 10.466318\n",
      "Eval over 10 episodes: mean smooth 36.479884 ± 0.398708\n",
      "Eval over 10 episodes: mean smoot2 1.080228 ± 0.179821\n",
      "Eval over 10 episodes: mean smooth3 2.695170 ± 0.034253\n",
      "\n",
      "Eval over 10 episodes: mean reward 788.907471 ± 7.106609\n",
      "Eval over 10 episodes: mean smooth 36.291891 ± 0.348469\n",
      "Eval over 10 episodes: mean smoot2 1.077654 ± 0.177009\n",
      "Eval over 10 episodes: mean smooth3 2.688746 ± 0.027719\n",
      "\n",
      "Eval over 10 episodes: mean reward 784.938110 ± 5.957300\n",
      "Eval over 10 episodes: mean smooth 36.368164 ± 0.392844\n",
      "Eval over 10 episodes: mean smoot2 1.081345 ± 0.174555\n",
      "Eval over 10 episodes: mean smooth3 2.697955 ± 0.024058\n",
      "\n",
      "Eval over 10 episodes: mean reward 788.824097 ± 12.748711\n",
      "Eval over 10 episodes: mean smooth 36.507449 ± 0.428580\n",
      "Eval over 10 episodes: mean smoot2 1.089690 ± 0.175786\n",
      "Eval over 10 episodes: mean smooth3 2.718777 ± 0.044766\n",
      "\n",
      "Eval over 10 episodes: mean reward 784.061890 ± 12.252577\n",
      "Eval over 10 episodes: mean smooth 36.464578 ± 0.482651\n",
      "Eval over 10 episodes: mean smoot2 1.089875 ± 0.174846\n",
      "Eval over 10 episodes: mean smooth3 2.719239 ± 0.046288\n",
      "\n",
      "Eval over 10 episodes: mean reward 778.259338 ± 19.760153\n",
      "Eval over 10 episodes: mean smooth 36.499855 ± 0.494778\n",
      "Eval over 10 episodes: mean smoot2 1.093733 ± 0.170395\n",
      "Eval over 10 episodes: mean smooth3 2.728864 ± 0.051454\n",
      "\n",
      "Eval over 10 episodes: mean reward 789.638000 ± 7.493102\n",
      "Eval over 10 episodes: mean smooth 36.531457 ± 0.373616\n",
      "Eval over 10 episodes: mean smoot2 1.078048 ± 0.178588\n",
      "Eval over 10 episodes: mean smooth3 2.689730 ± 0.039938\n",
      "\n",
      "Eval over 10 episodes: mean reward 781.489441 ± 5.690169\n",
      "Eval over 10 episodes: mean smooth 36.260962 ± 0.555226\n",
      "Eval over 10 episodes: mean smoot2 1.079462 ± 0.177288\n",
      "Eval over 10 episodes: mean smooth3 2.693258 ± 0.042871\n",
      "\n",
      "Eval over 10 episodes: mean reward 794.136475 ± 7.685799\n",
      "Eval over 10 episodes: mean smooth 36.218357 ± 0.333360\n",
      "Eval over 10 episodes: mean smoot2 1.078540 ± 0.182790\n",
      "Eval over 10 episodes: mean smooth3 2.690958 ± 0.033276\n",
      "\n",
      "Eval over 10 episodes: mean reward 789.969299 ± 7.637829\n",
      "Eval over 10 episodes: mean smooth 36.349493 ± 0.368271\n",
      "Eval over 10 episodes: mean smoot2 1.080095 ± 0.177118\n",
      "Eval over 10 episodes: mean smooth3 2.694837 ± 0.040350\n",
      "\n",
      "\n",
      "Best Reward: 794.136475 ± 7.685799\n",
      "Best Smooth1: 36.218357 ± 0.333360\n",
      "Best Smooth2: 1.078540 ± 0.182790\n",
      "Best Smooth3: 2.690958 ± 0.033276\n",
      "Best Seed: 8\n",
      "/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/2gradcaps/SAC-2gradcaps-lmd0.1-walker-run-v0-seed1-2025_09_30_22h46m56s__minmax/weights/best_reward-791.4241_smooth-36.1689.w\n",
      "Eval over 10 episodes: mean reward 788.323730 ± 13.554113\n",
      "Eval over 10 episodes: mean smooth 36.509386 ± 0.384957\n",
      "Eval over 10 episodes: mean smoot2 1.093660 ± 0.190085\n",
      "Eval over 10 episodes: mean smooth3 2.728680 ± 0.046858\n",
      "\n",
      "Eval over 10 episodes: mean reward 786.633911 ± 9.475581\n",
      "Eval over 10 episodes: mean smooth 36.273509 ± 0.490700\n",
      "Eval over 10 episodes: mean smoot2 1.088095 ± 0.191827\n",
      "Eval over 10 episodes: mean smooth3 2.714796 ± 0.046993\n",
      "\n",
      "Eval over 10 episodes: mean reward 784.277100 ± 7.670810\n",
      "Eval over 10 episodes: mean smooth 36.375996 ± 0.353886\n",
      "Eval over 10 episodes: mean smoot2 1.085662 ± 0.194381\n",
      "Eval over 10 episodes: mean smooth3 2.708728 ± 0.038273\n",
      "\n",
      "Eval over 10 episodes: mean reward 793.005737 ± 8.421308\n",
      "Eval over 10 episodes: mean smooth 36.236548 ± 0.354607\n",
      "Eval over 10 episodes: mean smoot2 1.082241 ± 0.194860\n",
      "Eval over 10 episodes: mean smooth3 2.700191 ± 0.035258\n",
      "\n",
      "Eval over 10 episodes: mean reward 783.189575 ± 19.290253\n",
      "Eval over 10 episodes: mean smooth 36.644670 ± 0.387608\n",
      "Eval over 10 episodes: mean smoot2 1.090210 ± 0.198914\n",
      "Eval over 10 episodes: mean smooth3 2.720073 ± 0.036609\n",
      "\n",
      "Eval over 10 episodes: mean reward 783.987488 ± 12.583722\n",
      "Eval over 10 episodes: mean smooth 36.713561 ± 0.291586\n",
      "Eval over 10 episodes: mean smoot2 1.096475 ± 0.192364\n",
      "Eval over 10 episodes: mean smooth3 2.735705 ± 0.027745\n",
      "\n",
      "Eval over 10 episodes: mean reward 785.686890 ± 7.884034\n",
      "Eval over 10 episodes: mean smooth 36.551321 ± 0.298252\n",
      "Eval over 10 episodes: mean smoot2 1.076960 ± 0.196694\n",
      "Eval over 10 episodes: mean smooth3 2.687015 ± 0.040810\n",
      "\n",
      "Eval over 10 episodes: mean reward 783.004333 ± 5.732067\n",
      "Eval over 10 episodes: mean smooth 36.174232 ± 0.411566\n",
      "Eval over 10 episodes: mean smoot2 1.076805 ± 0.192897\n",
      "Eval over 10 episodes: mean smooth3 2.686627 ± 0.038762\n",
      "\n",
      "Eval over 10 episodes: mean reward 787.592896 ± 11.046168\n",
      "Eval over 10 episodes: mean smooth 36.391652 ± 0.378703\n",
      "Eval over 10 episodes: mean smoot2 1.087867 ± 0.189699\n",
      "Eval over 10 episodes: mean smooth3 2.714229 ± 0.034995\n",
      "\n",
      "Eval over 10 episodes: mean reward 788.789917 ± 7.202049\n",
      "Eval over 10 episodes: mean smooth 36.350518 ± 0.348672\n",
      "Eval over 10 episodes: mean smoot2 1.086680 ± 0.194288\n",
      "Eval over 10 episodes: mean smooth3 2.711267 ± 0.017757\n",
      "\n",
      "\n",
      "Best Reward: 793.005737 ± 8.421308\n",
      "Best Smooth1: 36.236548 ± 0.354607\n",
      "Best Smooth2: 1.082241 ± 0.194860\n",
      "Best Smooth3: 2.700191 ± 0.035258\n",
      "Best Seed: 3\n",
      "/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/3gradcaps/SAC-3gradcaps-lmd0.1-walker-run-v0-seed1-2025_09_30_14h50m11s__minmax/weights/best_reward-799.5089_smooth-37.5638.w\n",
      "Eval over 10 episodes: mean reward 799.624268 ± 9.152903\n",
      "Eval over 10 episodes: mean smooth 37.626278 ± 0.473744\n",
      "Eval over 10 episodes: mean smoot2 1.113137 ± 0.219447\n",
      "Eval over 10 episodes: mean smooth3 2.777278 ± 0.040882\n",
      "\n",
      "Eval over 10 episodes: mean reward 723.950317 ± 208.531693\n",
      "Eval over 10 episodes: mean smooth 34.770137 ± 8.252187\n",
      "Eval over 10 episodes: mean smoot2 1.037455 ± 0.186123\n",
      "Eval over 10 episodes: mean smooth3 2.588451 ± 0.577277\n",
      "\n",
      "Eval over 10 episodes: mean reward 791.467590 ± 13.819752\n",
      "Eval over 10 episodes: mean smooth 37.356716 ± 0.510199\n",
      "Eval over 10 episodes: mean smoot2 1.106248 ± 0.212466\n",
      "Eval over 10 episodes: mean smooth3 2.760088 ± 0.039886\n",
      "\n",
      "Eval over 10 episodes: mean reward 798.265259 ± 10.511070\n",
      "Eval over 10 episodes: mean smooth 37.387028 ± 0.367716\n",
      "Eval over 10 episodes: mean smoot2 1.113405 ± 0.220271\n",
      "Eval over 10 episodes: mean smooth3 2.777946 ± 0.032097\n",
      "\n",
      "Eval over 10 episodes: mean reward 789.061157 ± 20.631582\n",
      "Eval over 10 episodes: mean smooth 37.555861 ± 0.463361\n",
      "Eval over 10 episodes: mean smoot2 1.119193 ± 0.217434\n",
      "Eval over 10 episodes: mean smooth3 2.792387 ± 0.040382\n",
      "\n",
      "Eval over 10 episodes: mean reward 791.398621 ± 14.165492\n",
      "Eval over 10 episodes: mean smooth 37.616354 ± 0.490536\n",
      "Eval over 10 episodes: mean smoot2 1.109365 ± 0.215650\n",
      "Eval over 10 episodes: mean smooth3 2.767865 ± 0.031775\n",
      "\n",
      "Eval over 10 episodes: mean reward 772.915833 ± 72.468719\n",
      "Eval over 10 episodes: mean smooth 36.445662 ± 2.214595\n",
      "Eval over 10 episodes: mean smoot2 1.090137 ± 0.218877\n",
      "Eval over 10 episodes: mean smooth3 2.719891 ± 0.123364\n",
      "\n",
      "Eval over 10 episodes: mean reward 782.671204 ± 13.981524\n",
      "Eval over 10 episodes: mean smooth 37.448522 ± 0.279422\n",
      "Eval over 10 episodes: mean smoot2 1.112012 ± 0.219307\n",
      "Eval over 10 episodes: mean smooth3 2.774469 ± 0.033422\n",
      "\n",
      "Eval over 10 episodes: mean reward 797.116516 ± 9.718843\n",
      "Eval over 10 episodes: mean smooth 37.640697 ± 0.525423\n",
      "Eval over 10 episodes: mean smoot2 1.117599 ± 0.217633\n",
      "Eval over 10 episodes: mean smooth3 2.788409 ± 0.062659\n",
      "\n",
      "Eval over 10 episodes: mean reward 724.565735 ± 204.359238\n",
      "Eval over 10 episodes: mean smooth 34.906584 ± 7.308218\n",
      "Eval over 10 episodes: mean smoot2 1.035159 ± 0.200109\n",
      "Eval over 10 episodes: mean smooth3 2.582722 ± 0.511447\n",
      "\n",
      "\n",
      "Best Reward: 799.624268 ± 9.152903\n",
      "Best Smooth1: 37.626278 ± 0.473744\n",
      "Best Smooth2: 1.113137 ± 0.219447\n",
      "Best Smooth3: 2.777278 ± 0.040882\n",
      "Best Seed: 0\n",
      "/home/adsl/Workspace/cleanrl/cleanrl/runs/SAC/4gradcaps/SAC-4gradcaps-lmd0.1-walker-run-v0-seed1-2025_09_30_19h57m06s__minmax/weights/best_reward-793.8300_smooth-37.0779.w\n",
      "Eval over 10 episodes: mean reward 791.711548 ± 15.008801\n",
      "Eval over 10 episodes: mean smooth 37.237713 ± 0.594549\n",
      "Eval over 10 episodes: mean smoot2 1.090996 ± 0.179326\n",
      "Eval over 10 episodes: mean smooth3 2.722034 ± 0.059622\n",
      "\n",
      "Eval over 10 episodes: mean reward 789.629150 ± 9.748629\n",
      "Eval over 10 episodes: mean smooth 37.086084 ± 0.459105\n",
      "Eval over 10 episodes: mean smoot2 1.087821 ± 0.177556\n",
      "Eval over 10 episodes: mean smooth3 2.714114 ± 0.037332\n",
      "\n",
      "Eval over 10 episodes: mean reward 788.405273 ± 9.523503\n",
      "Eval over 10 episodes: mean smooth 37.211639 ± 0.454520\n",
      "Eval over 10 episodes: mean smoot2 1.093618 ± 0.176855\n",
      "Eval over 10 episodes: mean smooth3 2.728577 ± 0.031115\n",
      "\n",
      "Eval over 10 episodes: mean reward 791.214722 ± 7.309913\n",
      "Eval over 10 episodes: mean smooth 37.217578 ± 0.386273\n",
      "Eval over 10 episodes: mean smoot2 1.091973 ± 0.179048\n",
      "Eval over 10 episodes: mean smooth3 2.724472 ± 0.030396\n",
      "\n",
      "Eval over 10 episodes: mean reward 781.352173 ± 13.184398\n",
      "Eval over 10 episodes: mean smooth 37.335730 ± 0.615802\n",
      "Eval over 10 episodes: mean smoot2 1.102658 ± 0.169886\n",
      "Eval over 10 episodes: mean smooth3 2.751132 ± 0.064054\n",
      "\n",
      "Eval over 10 episodes: mean reward 783.079773 ± 14.564767\n",
      "Eval over 10 episodes: mean smooth 37.312612 ± 0.403604\n",
      "Eval over 10 episodes: mean smoot2 1.093923 ± 0.176258\n",
      "Eval over 10 episodes: mean smooth3 2.729338 ± 0.039985\n",
      "\n",
      "Eval over 10 episodes: mean reward 786.525024 ± 12.769325\n",
      "Eval over 10 episodes: mean smooth 37.373906 ± 0.475817\n",
      "Eval over 10 episodes: mean smoot2 1.092458 ± 0.183565\n",
      "Eval over 10 episodes: mean smooth3 2.725682 ± 0.042167\n",
      "\n",
      "Eval over 10 episodes: mean reward 782.616089 ± 13.139011\n",
      "Eval over 10 episodes: mean smooth 37.239105 ± 0.391531\n",
      "Eval over 10 episodes: mean smoot2 1.085175 ± 0.175435\n",
      "Eval over 10 episodes: mean smooth3 2.707512 ± 0.045946\n",
      "\n",
      "Eval over 10 episodes: mean reward 792.576111 ± 11.487295\n",
      "Eval over 10 episodes: mean smooth 37.161773 ± 0.500203\n",
      "Eval over 10 episodes: mean smoot2 1.085134 ± 0.179308\n",
      "Eval over 10 episodes: mean smooth3 2.707408 ± 0.065520\n",
      "\n",
      "Eval over 10 episodes: mean reward 789.680786 ± 8.793346\n",
      "Eval over 10 episodes: mean smooth 37.186947 ± 0.535384\n",
      "Eval over 10 episodes: mean smoot2 1.092465 ± 0.178685\n",
      "Eval over 10 episodes: mean smooth3 2.725700 ± 0.043837\n",
      "\n",
      "\n",
      "Best Reward: 792.576111 ± 11.487295\n",
      "Best Smooth1: 37.161773 ± 0.500203\n",
      "Best Smooth2: 1.085134 ± 0.179308\n",
      "Best Smooth3: 2.707408 ± 0.065520\n",
      "Best Seed: 8\n"
     ]
    }
   ],
   "source": [
    "for algo in ['SAC']:\n",
    "    for model in ['-vanilla-', '-caps-', '-gradcaps-', '-2gradcaps-', '-3gradcaps-', '-4gradcaps-']:\n",
    "        env = 'walker-run-v0'\n",
    "\n",
    "        if algo == 'SAC':\n",
    "            from cleanrl.sac_continuous_action import Actor, make_env\n",
    "        elif algo == 'TD3':\n",
    "            from cleanrl.td3_continuous_action import Actor, make_env\n",
    "        elif algo == 'DDPG':\n",
    "            from cleanrl.ddpg_continuous_action import Actor, make_env\n",
    "\n",
    "        best_reward = -10000\n",
    "\n",
    "        for filename in filenames:\n",
    "            if (algo in filename) and (model in filename) and env in filename and 'best_reward' in filename:\n",
    "                reward = float(filename.split('best_reward-')[-1].split('_')[0])\n",
    "                smooth = float(filename.split('smooth-')[-1].split('.w')[0])\n",
    "                if reward > best_reward:\n",
    "                    best_reward = reward\n",
    "                    best_filename = filename\n",
    "\n",
    "        print(best_filename)\n",
    "        best_reward = -10000\n",
    "\n",
    "        for seed in range(10):\n",
    "            rewards, smooths1, smooths2, smooths3 = evaluate(\n",
    "                best_filename,\n",
    "                make_env,\n",
    "                \"dm_control/walker-run-v0\",\n",
    "                algo=algo,\n",
    "                eval_episodes=10,\n",
    "                run_name=f\"eval\",\n",
    "                device=\"cuda\",\n",
    "                capture_video=False,\n",
    "                seed=seed\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            reward = np.mean(rewards)\n",
    "            \n",
    "            if reward > best_reward:\n",
    "                best_reward = reward\n",
    "                best_rewards = rewards\n",
    "                best_smooths1 = smooths1\n",
    "                best_smooths2 = smooths2\n",
    "                best_smooths3 = smooths3\n",
    "                best_seed = seed\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(f'Best Reward: {np.mean(best_rewards):.6f} ± {np.std(best_rewards):.6f}')\n",
    "        print(f'Best Smooth1: {np.mean(best_smooths1)*100:.6f} ± {np.std(best_smooths1)*100:.6f}')\n",
    "        print(f'Best Smooth2: {np.mean(best_smooths2)*100:.6f} ± {np.std(best_smooths2)*100:.6f}')\n",
    "        print(f'Best Smooth3: {np.mean(best_smooths3):.6f} ± {np.std(best_smooths3):.6f}')\n",
    "        print('Best Seed:', best_seed)\n",
    "        print()\n",
    "        # print(best_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
